---
title: "Big 5 Gender Predictor"
output:
  pdf_document: default
  html_notebook: default
---
```{r}
library('mda')
library('MASS')
library('klaR')
library('nnet')
library('kernlab')
library('caret')
library('e1071')
library("tidyverse")
library("keras")
```

```{r, warning = FALSE}
data <- read.csv("./data/data.csv") %>%
  filter(gender %in% c(1,2)) # General dataset
c_data <- read.csv("./data/custom_data.csv") # Custom user dataset
num_cust_data <- nrow(c_data) # Track number of custom user entries in the dataset
str(data)
summary(data)

# Shuffle dataset, append custom users
set.seed(5)
n <- nrow(data)
data <- rbind(c_data,data[sample(n),])
```
Only select rows with predictable genders. Non-specified could also be considered if there were more samples, but at the time of writing this only **102** observations are present in the data set. In the original question set several questions were posed such that they measured the low-end of the trait rather than the high end. These values have been reversed.

Trait Definitions:  
O: Low Openness           -> High Openness  
C: Low Conscientiousness  -> High Conscientiousness   
E: Intraversion           -> Extraversion  
A: Disagreeableness       -> Agreeableness  
N: Low Neuroticism        -> High Neuroticism   

Define R function to correct for question 
```{r}
qCorrect <- function(n){
  switch(as.character(n),
         '1' = 5,
         '2' = 4,
         '3' = 3,
         '4' = 2,
         '5' = 1, 0)
}
qCorrect <- Vectorize(qCorrect) # Vectorize function to allow interoperation with dplyr::mutate
```

```{r}
# Flip certain answer using qCorrect to align with traits as defined previously
data_qc <- data %>%
              mutate_at(
                .vars = c("E2", "E4", "E6", "E8", "E10", "N2", 
                          "N4", "A1", "A3", "A5", "A7", "C2", 
                          "C4", "C6", "C8", "O2", "O4", "O6"), funs(qCorrect)) %>%
              mutate(sex = ifelse(gender == 1, 0, 1)) 
#str(data_qc)
```
Calculate score based on 10 relevant questions to metric
```{r}
data_rs <- data_qc %>% 
            mutate(o_sum = rowSums(.[8:17]))  %>%
            mutate(c_sum = rowSums(.[18:27])) %>% 
            mutate(e_sum = rowSums(.[28:37])) %>% 
            mutate(a_sum = rowSums(.[38:47])) %>%
            mutate(n_sum = rowSums(.[48:57]))
summary(data_rs[58:63])
```
Calculate percentile scoring
```{r}
data_ps <- data_rs %>%
            # mutate_at(.vars = c("o_sum","c_sum","e_sum","a_sum","n_sum"), funs(percent_rank)) 
            # Can replicate the below functionality with the above line, but this overwrites the columns
            mutate(o_ps = percent_rank(o_sum)) %>%
            mutate(c_ps = percent_rank(c_sum)) %>%
            mutate(e_ps = percent_rank(e_sum)) %>%
            mutate(a_ps = percent_rank(a_sum)) %>%
            mutate(n_ps = percent_rank(n_sum))

# Select useful columns
big5 <- data_ps[,c(59,65:69)] # percent scores and sex id
str(big5)
```

```{r, warning=FALSE}
# train_indices <- (num_cust_data +1):round(0.7*n)
# train_x <- scale(data.matrix(big5$x[train_indices,]))
# train_y <- big5$y[train_indices]
# str(train_x)
# str(train_y)

# test_indices <- c(1:num_cust_data,(round(0.7*n)+1):n)
# test_x <- scale(data.matrix(big5$x[test_indices,]))
# test_y <- big5$y[test_indices]
# str(test_x)
# str(test_y)

# train_subset_indices <- 1:50
# train_x_subset <- scale(data.matrix(big5$x[train_subset_indices,]))
# train_y_subset <- big5$y[train_subset_indices]
# str(train_x_subset)
# str(train_y_subset) 


train_indices <- (num_cust_data + 1):round(0.7*n) # ~70% of dataset
test_indices <- c(1:num_cust_data,(round(0.7*n)+1):n) # ~30% of dataset
train <- big5[train_indices,]
test  <- big5[test_indices,]
#str(cv_a)
str(train)
str(test)
```

Mixture Discriminant Analysis
```{r, message=FALSE, warning=FALSE}
mda_fit <- mda(sex~., data = train_a)
summary(mda_fit)
mda_predictions <-predict(mda_fit,test_a[,2:6])
pred_table <-table(mda_predictions,test_a$sex)
confusionMatrix(as.factor(mda_predictions),as.factor(test_a$sex))
# 0.6642 accuracy
```

Quadratic Discriminant Analysis
```{r, message=FALSE, warning=FALSE}
qda_fit <- qda(sex~., data = train_a)
summary(qda_fit)
qda_predictions <-predict(qda_fit,test_a[,2:6])$class
confusionMatrix(as.factor(qda_predictions),as.factor(test_a$sex))
# 0.6675 accuracy
```

Regularized Discriminant Analysis
```{r, message=FALSE, warning=FALSE}
rda_fit <- rda(sex~., data = train_a, gamma = 0.05, lambda = 0.01)
summary(qda_fit)
rda_predictions <-predict(rda_fit,test_a[,2:6])$class
confusionMatrix(as.factor(rda_predictions),as.factor(test_a$sex))
# 0.667 accuracy
```

Neural Net
```{r, message=FALSE, warning=FALSE}
nnet_fit <- nnet(as.factor(sex)~., data=train_a, size=4, decay=0.0001, maxit=500)
summary(nnet_fit)
str(nnet_fit)

nnet_predictions <-predict(nnet_fit,test_a[,2:6], type='class')
confusionMatrix(as.factor(nnet_predictions),as.factor(test_a$sex))
# 0.6693 accuracy
```

Flexible Discriminant Analysis
```{r, message=FALSE, warning=FALSE}
fda_fit <- fda(as.factor(sex)~., data=train_a)
summary(fda_fit)
str(fda_fit)

fda_predictions <-predict(fda_fit,test_a[,2:6])
confusionMatrix(as.factor(fda_predictions),as.factor(test_a$sex))
# 0.666 accuracy
```

Support Vector Machine
```{r, message=FALSE, warning=FALSE}
svm_fit <- ksvm(as.factor(sex)~., data=train_a)
svm_predictions <- predict(svm_fit, test_a[,2:6], type='response')
table(svm_predictions, test_a$sex)
confusionMatrix(as.factor(svm_predictions),as.factor(test_a$sex))
# 0.6721 accuracy
```

k-Nearest Neighbours
```{r, message=FALSE, warning=FALSE}
knn_fit <- knn3(as.factor(sex)~., data=train_a, k = 10)
knn_predictions <- predict(knn_fit, test_a[,2:6], type='class')
table(knn_predictions, test_a$sex)
confusionMatrix(as.factor(knn_predictions),as.factor(test_a$sex))
# 0.6295 accuracy
```

Naive Bayes
```{r, message=FALSE, warning=FALSE, include=FALSE}
nb_fit <- naiveBayes(as.factor(sex)~., data=train_a)
nb_predictions <- predict(nb_fit, test_a[,2:6], type='class')
table(nb_predictions, test_a$sex)
confusionMatrix(as.factor(nb_predictions),as.factor(test_a$sex))
# 0.6675 accuracy
```


Neural Network Model using 'keras' package
```{r, message=FALSE, warning=FALSE}
# Model initialization
# epochs <- 15
# batch_size <- 15
# initializer_random_normal() # Initial weighting initialization
# 
# model <- keras_model_sequential()
# model %>%
#   layer_dense(units = 5, 
#               input_shape = c(5), 
#               name = "Input_Layer") %>%
#   layer_activation(activation = 'sigmoid') %>%3
#   layer_dense(units = 7,
#               name = "Dense_2",
#               kernel_regularizer = ) %>%
#   layer_activation(activation = 'relu') %>%
#   layer_dense(units = 7) %>%
#   layer_activation(activation = 'sigmoid')
# 
# model %>% compile(
#   loss = loss_binary_crossentropy,
#   optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
#   metrics = metric_binary_accuracy 
# )
# 
# # validation_model <- model
# # validation_model %>% fit(
# #   x = train_x_subset, y = train_y_subset,
# #   epochs = epochs,
# #   batch_size = batch_size,
# #   verbose = 2
# # )  
# #summary(validation_model)
# 
# model %>% fit(
#   x = train_x, y = train_y,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2,
#   validation_split = 0.1
# )

```

```{r}
# weightHistory <- R6::R6Class("weightHistory",
#   inherit = KerasCallback,
#   public = list(
#     weights = NULL,
#     on_batch_end = function(batch, logs = list()) {
#       for(i in 1:3){
#         var(self$weights[[i]],1)
#       }
#     }
# ))
```

```{r}
# validation_model %>% evaluate(test_x, test_y, verbose = 0)
# model %>% evaluate(test_x, test_y, verbose = 0)

```
References:
https://engineering.semantics3.com/debugging-neural-networks-a-checklist-ca52e11151ec  
https://keras.rstudio.com/articles/functional_api.html#multi-input-and-multi-output-models  
https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c  
https://machinelearningmastery.com/non-linear-classification-in-r