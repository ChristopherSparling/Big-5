---
title: "Big 5 Gender Predictor"
output:
  pdf_document: default
---
```{r load_libraries, message=FALSE}
library('mda')
library('MASS')
library('klaR')
library('nnet')
library('kernlab')
library('caret')
library('e1071')
library("tidyverse")
library("keras")
library("reshape2")
```

```{r read_data, warning = FALSE}
set.seed(5)
data <- read.csv("./data/data.csv") %>%
  filter(gender %in% c(1,2)) # General dataset
c_data <- read.csv("./data/custom_data.csv") # Custom user dataset
num_cust_data <- nrow(c_data) # Track number of custom user entries in the dataset
cust_preds <- data.frame(name = c_data[1:num_cust_data,"name"]) # Placeholder dataframe for later-generated predictions
n <-nrow(data)
data <- rbind(c_data,data[sample(nrow(data)),]) # Shuffle dataset, prepend custom users
```
Only select rows with predictable genders. Non-specified could also be considered if there were more samples, but at the time of writing this only **102** observations are present in the data set. In the original question set several questions were posed such that they measured the low-end of the trait rather than the high end. These values have been reversed.

Trait Definitions:  
O: Low Openness           -> High Openness  
C: Low Conscientiousness  -> High Conscientiousness   
E: Intraversion           -> Extraversion  
A: Disagreeableness       -> Agreeableness  
N: Low Neuroticism        -> High Neuroticism   

Define R function to correct for question 
```{r define_qCorrect}
qCorrect <- function(n){
  switch(as.character(n),
         '1' = 5,
         '2' = 4,
         '3' = 3,
         '4' = 2,
         '5' = 1, 0)
}
qCorrect <- Vectorize(qCorrect) # Vectorize function to allow interoperation with dplyr::mutate
```

```{r flip_questions}
# Flip certain answer using qCorrect to align with traits as defined previously
data_qc <- data %>%
              mutate_at(
                .vars = c("E2", "E4", "E6", "E8", "E10", "N2", 
                          "N4", "A1", "A3", "A5", "A7", "C2", 
                          "C4", "C6", "C8", "O2", "O4", "O6"), funs(qCorrect)) %>%
              mutate(sex = ifelse(gender == 1, 0, 1)) 
```

Calculate score based on 10 relevant questions to metric
```{r find_rowsums}
data_rs <- data_qc %>% 
            mutate(o_sum = rowSums(.[48:57])) %>%
            mutate(c_sum = rowSums(.[38:47])) %>% 
            mutate(e_sum = rowSums(.[ 8:17])) %>% 
            mutate(a_sum = rowSums(.[28:37])) %>%
            mutate(n_sum = rowSums(.[18:27]))
str(data_rs[58:64])
```
Calculate percentile scoring
```{r calculate_percentiles}
data_ps <- data_rs %>%
            mutate(o_ps = percent_rank(o_sum)) %>%
            mutate(c_ps = percent_rank(c_sum)) %>%
            mutate(e_ps = percent_rank(e_sum)) %>%
            mutate(a_ps = percent_rank(a_sum)) %>%
            mutate(n_ps = percent_rank(n_sum))

# Select useful columns
big5 <- data_ps[,c(58,59,65:69)]
str(big5)
```

Some basic data exploration
```{r data_exploration_heatmap, warning=FALSE}
# Correlation Heatmap
corr_data <- big5[,3:7]
names(corr_data) <- c("Openness", "Concientiousness", "Extraversion", "Agreeableness", "Neuroticism")
trait_cor <- round(cor(corr_data),2)
trait_cor[lower.tri(trait_cor)] <- NA
melted_trait_cor <- melt(trait_cor, na.rm = TRUE)
names(melted_trait_cor) <- c("Trait A", "Trait B", "Value")

ggplot(data = melted_trait_cor, aes(`Trait B`, `Trait A`, fill = Value)) +
   geom_tile(color = "white") +
   scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                        midpoint = 0, limit = c(-1,1), space = "Lab", 
                        name="Pearson\nCorrelation") +
   theme_minimal() + 
   theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1)) +
   geom_text(aes(`Trait B`, `Trait A`, label = Value), color = "black", size = 4) +
   coord_fixed()
```

```{r data_exploration_gender_diff, warning=FALSE}

# Personality Averages by Gender
gender_mean <- big5[,2:7] %>% 
  group_by(sex) %>%
  summarise_all(funs(mean))

gender_diff <- (gender_mean[1,2:6] - gender_mean[2,2:6]) * 100 # difference between men and women
gender_diff
```

Organize testing/training data
```{r test_train_data, warning=FALSE}
train_indices <- (num_cust_data + 1):round(0.7*n) # ~70% of dataset
test_indices <- c(1:num_cust_data,(round(0.7*n)+1):n) # ~30% of dataset
train <- big5[train_indices,2:7]
test  <- big5[test_indices,2:7]
str(train)
str(test)
```

Mixture Discriminant Analysis
```{r mda, warning=FALSE}
mda_fit <- mda(sex~., data = train)
mda_predictions <-predict(mda_fit,test[,2:6])
pred_table <- table(mda_predictions,test$sex)
confusionMatrix(as.factor(mda_predictions),as.factor(test$sex))
cust_preds$mda <- mda_predictions[1:num_cust_data]
```

Quadratic Discriminant Analysis
```{r qda, warning=FALSE}
qda_fit <- qda(sex~., data = train)
qda_predictions <-predict(qda_fit,test[,2:6])$class
confusionMatrix(as.factor(qda_predictions),as.factor(test$sex))
cust_preds$qda <- qda_predictions[1:num_cust_data]
```

Regularized Discriminant Analysis
```{r rda, warning=FALSE}
rda_fit <- rda(sex~., data = train, gamma = 0.05, lambda = 0.01)
rda_predictions <-predict(rda_fit,test[,2:6])$class
confusionMatrix(as.factor(rda_predictions),as.factor(test$sex))
cust_preds$rda <- rda_predictions[1:num_cust_data]
```

Neural Net
```{r nnet, warning=FALSE}
nnet_fit <- nnet(as.factor(sex)~., data=train, size=4, decay=0.0001, maxit=500)
nnet_predictions <-predict(nnet_fit,test[,2:6], type='class')
confusionMatrix(as.factor(nnet_predictions),as.factor(test$sex))
cust_preds$nnet <- nnet_predictions[1:num_cust_data]
```

Flexible Discriminant Analysis
```{r fda, warning=FALSE}
fda_fit <- fda(as.factor(sex)~., data=train)
fda_predictions <-predict(fda_fit,test[,2:6])
confusionMatrix(as.factor(fda_predictions),as.factor(test$sex))
cust_preds$fda <- fda_predictions[1:num_cust_data]
```

Support Vector Machine
```{r svm, message=FALSE, warning=FALSE}
svm_fit <- ksvm(as.factor(sex)~., data=train)
svm_predictions <- predict(svm_fit, test[,2:6], type='response')
confusionMatrix(as.factor(svm_predictions),as.factor(test$sex))
cust_preds$svm <- svm_predictions[1:num_cust_data]
```

k-Nearest Neighbours
```{r knn, warning=FALSE}
knn_fit <- knn3(as.factor(sex)~., data=train, k = 10)
knn_predictions <- predict(knn_fit, test[,2:6], type='class')
confusionMatrix(as.factor(knn_predictions),as.factor(test$sex))
cust_preds$knn <- knn_predictions[1:num_cust_data]
```

Naive Bayes
```{r nb, warning=FALSE}
nb_fit <- naiveBayes(as.factor(sex)~., data=train)
nb_predictions <- predict(nb_fit, test[,2:6], type='class')
confusionMatrix(as.factor(nb_predictions),as.factor(test$sex))
cust_preds$nb <- nb_predictions[1:num_cust_data]
```

```{r keras_ann, include=FALSE, message=FALSE, warning=FALSE}
#Neural Network Model using 'keras' package

# Model initialization
# epochs <- 15
# batch_size <- 15
# initializer_random_normal() # Initial weighting initialization
# 
# model <- keras_model_sequential()
# model %>%
#   layer_dense(units = 5, 
#               input_shape = c(5), 
#               name = "Input_Layer") %>%
#   layer_activation(activation = 'sigmoid') %>%3
#   layer_dense(units = 7,
#               name = "Dense_2",
#               kernel_regularizer = ) %>%
#   layer_activation(activation = 'relu') %>%
#   layer_dense(units = 7) %>%
#   layer_activation(activation = 'sigmoid')
# 
# model %>% compile(
#   loss = loss_binary_crossentropy,
#   optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
#   metrics = metric_binary_accuracy 
# )
# 
# # validation_model <- model
# # validation_model %>% fit(
# #   x = train_x_subset, y = train_y_subset,
# #   epochs = epochs,
# #   batch_size = batch_size,
# #   verbose = 2
# # )  
# #summary(validation_model)
# 
# model %>% fit(
#   x = train_x, y = train_y,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2,
#   validation_split = 0.1
# )

```

```{r define_weightHistory, include=FALSE}
# weightHistory <- R6::R6Class("weightHistory",
#   inherit = KerasCallback,
#   public = list(
#     weights = NULL,
#     on_batch_end = function(batch, logs = list()) {
#       for(i in 1:3){
#         var(self$weights[[i]],1)
#       }
#     }
# ))
```

```{r evaluate_ann, include=FALSE}
# validation_model %>% evaluate(test_x, test_y, verbose = 0)
# model %>% evaluate(test_x, test_y, verbose = 0)
```

Custom User Predictions
```{r cust_user_preds}
cust_preds
```
References:  
https://engineering.semantics3.com/debugging-neural-networks-a-checklist-ca52e11151ec
https://keras.rstudio.com/articles/functional_api.html#multi-input-and-multi-output-models  
https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c  
https://machinelearningmastery.com/non-linear-classification-in-r