#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>% # Regularization
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_4") %>% # Regularization
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01, decay = 0.001), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>% # Regularization
layer_activation_leaky_relu() %>%
# layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_4") %>% # Regularization
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01, decay = 0.001), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>% # Regularization
layer_activation_leaky_relu() %>%
# layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_4") %>% # Regularization
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation_leaky_relu() %>%
#layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_4") %>%
layer_dense(units = 7,
name = "Dense_4") %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation_leaky_relu() %>%
#layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_4") %>%
layer_dense(units = 7,
name = "Dense_5") %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2") %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
model
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
model$layers
model$layers[[1]]
model$layers[[1]]$get_weights()
var(model$layers[[1]]$get_weights())
model$layers[[1]]$get_weights()
model$layers[[1]]$[[1]]$get_weights()
model$layers[[1]][[1]]$get_weights())
model$layers[[1]][[1]]$get_weights()
model$layers[[1]][1]$get_weights()
model$layers[[1]]$get_weights()
model$layers[[2]]$get_weights()
model$layers[[2]]$get_weights()[[1]]
model$layers[[2]]$get_weights()$[[1]]
model$layers[[1]]$get_weights()
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
model$layers[[1]]$get_weights()
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2,
callbacks = callback_progbar_logger()
)
model$layers[[1]]$get_weights()
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'softmax') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2#,callbacks =
)
model$layers[[1]]$get_weights()
weightHistory <- R6::R6Class("weightHistory",
inherit = KerasCallback,
public = list(
weights = NULL,
on_batch_end = function(batch, logs = list()) {
for(i in 1:3){
var(self$weights[[i]],1)
}
}
))
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'softmax') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2,
callbacks = weightHistory
)
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = 'relu') %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'softmax') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
#,callbacks = weightHistory
)
model$layers[[1]]$get_weights()
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = activation_tanh()) %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'softmax') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = activation_tanh %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'softmax') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
# Model initialization
epochs <- 10
batch_size <- 15
initializer_random_normal() # Initial weighting initialization
model <- keras_model_sequential()
model %>%
layer_dense(units = 5,
input_shape = c(5),
name = "Input_Layer") %>%
layer_activation(activation = activation_tanh) %>%
layer_dense(units = 7,
name = "Dense_2",
kernel_regularizer = ) %>%
layer_activation(activation = 'softmax') %>%
layer_dense(units = 7) %>%
layer_activation(activation = 'sigmoid')
model %>% compile(
loss = loss_binary_crossentropy,
optimizer = optimizer_rmsprop(lr = 0.01), # Modified learning rate, being checked in logarithmic steps
metrics = metric_binary_accuracy
)
# validation_model <- model
# validation_model %>% fit(
#   x = train_x_subset, y = train_y_subset,
#   epochs = epochs,
#   batch_size = batch_size,
#   verbose = 2
# )
#summary(validation_model)
model %>% fit(
x = train_x, y = train_y,
epochs = epochs,
batch_size = batch_size,
verbose = 2
#,callbacks = weightHistory
)
model$layers[[1]]$get_weights()
